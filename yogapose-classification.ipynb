{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-01T23:26:32.879106Z","iopub.execute_input":"2023-04-01T23:26:32.879543Z","iopub.status.idle":"2023-04-01T23:26:32.886396Z","shell.execute_reply.started":"2023-04-01T23:26:32.879504Z","shell.execute_reply":"2023-04-01T23:26:32.884850Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:14:50.156518Z","iopub.execute_input":"2023-04-14T15:14:50.156787Z","iopub.status.idle":"2023-04-14T15:15:01.356198Z","shell.execute_reply.started":"2023-04-14T15:14:50.156759Z","shell.execute_reply":"2023-04-14T15:15:01.354852Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set the paths for the dataset\ndataset_path = '/kaggle/input/yoga-poses-dataset/DATASET/'\ntrain_path = dataset_path + 'TRAIN/'\ntest_path = dataset_path + 'TEST/'","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:12.035949Z","iopub.execute_input":"2023-04-14T15:15:12.036335Z","iopub.status.idle":"2023-04-14T15:15:12.041754Z","shell.execute_reply.started":"2023-04-14T15:15:12.036302Z","shell.execute_reply":"2023-04-14T15:15:12.040531Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Set the image size and batch size\nimg_size = (224, 224)\nbatch_size = 32\n\n# Data augmentation for the training set\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:13.592429Z","iopub.execute_input":"2023-04-14T15:15:13.592810Z","iopub.status.idle":"2023-04-14T15:15:13.599118Z","shell.execute_reply.started":"2023-04-14T15:15:13.592778Z","shell.execute_reply":"2023-04-14T15:15:13.597600Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:19.661942Z","iopub.execute_input":"2023-04-14T15:15:19.662639Z","iopub.status.idle":"2023-04-14T15:15:19.667689Z","shell.execute_reply.started":"2023-04-14T15:15:19.662601Z","shell.execute_reply":"2023-04-14T15:15:19.666448Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Prepare the data generators for train and test sets\ntrain_generator = train_datagen.flow_from_directory(train_path,\n                                                    target_size=img_size,\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(test_path,\n                                                  target_size=img_size,\n                                                  batch_size=batch_size,\n                                                  class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:24.025053Z","iopub.execute_input":"2023-04-14T15:15:24.025773Z","iopub.status.idle":"2023-04-14T15:15:24.244988Z","shell.execute_reply.started":"2023-04-14T15:15:24.025736Z","shell.execute_reply":"2023-04-14T15:15:24.244029Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 1081 images belonging to 5 classes.\nFound 470 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a CNN model\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(train_generator.class_indices), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:25.835576Z","iopub.execute_input":"2023-04-14T15:15:25.836365Z","iopub.status.idle":"2023-04-14T15:15:29.926531Z","shell.execute_reply.started":"2023-04-14T15:15:25.836326Z","shell.execute_reply":"2023-04-14T15:15:29.925542Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lr_schedule = ExponentialDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=1000,\n    decay_rate=0.9)\n\noptimizer = Adam(learning_rate=lr_schedule)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:32.911311Z","iopub.execute_input":"2023-04-14T15:15:32.911930Z","iopub.status.idle":"2023-04-14T15:15:32.940049Z","shell.execute_reply.started":"2023-04-14T15:15:32.911891Z","shell.execute_reply":"2023-04-14T15:15:32.939104Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Compile the model\n\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:34.749680Z","iopub.execute_input":"2023-04-14T15:15:34.750042Z","iopub.status.idle":"2023-04-14T15:15:34.766401Z","shell.execute_reply.started":"2023-04-14T15:15:34.750008Z","shell.execute_reply":"2023-04-14T15:15:34.765319Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Set callbacks\nearly_stopping = EarlyStopping(patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=3)\nmodel_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:36.463761Z","iopub.execute_input":"2023-04-14T15:15:36.464790Z","iopub.status.idle":"2023-04-14T15:15:36.469878Z","shell.execute_reply.started":"2023-04-14T15:15:36.464751Z","shell.execute_reply":"2023-04-14T15:15:36.468383Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from PIL import ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:38.707996Z","iopub.execute_input":"2023-04-14T15:15:38.708706Z","iopub.status.idle":"2023-04-14T15:15:38.714378Z","shell.execute_reply.started":"2023-04-14T15:15:38.708666Z","shell.execute_reply":"2023-04-14T15:15:38.713215Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_generator,\n                    epochs=50,\n                    validation_data=test_generator,\n                    callbacks=[early_stopping, reduce_lr, model_checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-04-14T15:15:40.414240Z","iopub.execute_input":"2023-04-14T15:15:40.414609Z","iopub.status.idle":"2023-04-14T15:54:40.018112Z","shell.execute_reply.started":"2023-04-14T15:15:40.414576Z","shell.execute_reply":"2023-04-14T15:54:40.017011Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/50\n 5/34 [===>..........................] - ETA: 27s - loss: 2.5551 - accuracy: 0.2000","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/PIL/Image.py:997: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n","output_type":"stream"},{"name":"stdout","text":"34/34 [==============================] - 69s 2s/step - loss: 2.5674 - accuracy: 0.2118 - val_loss: 2.7394 - val_accuracy: 0.1660 - lr: 9.9653e-04\nEpoch 2/50\n34/34 [==============================] - 45s 1s/step - loss: 2.4449 - accuracy: 0.2118 - val_loss: 2.0686 - val_accuracy: 0.1745 - lr: 9.9297e-04\nEpoch 3/50\n34/34 [==============================] - 41s 1s/step - loss: 2.2869 - accuracy: 0.1943 - val_loss: 2.1108 - val_accuracy: 0.1851 - lr: 9.8941e-04\nEpoch 4/50\n34/34 [==============================] - 45s 1s/step - loss: 2.2131 - accuracy: 0.1785 - val_loss: 1.6828 - val_accuracy: 0.2426 - lr: 9.8588e-04\nEpoch 5/50\n34/34 [==============================] - 44s 1s/step - loss: 2.1099 - accuracy: 0.1998 - val_loss: 1.6019 - val_accuracy: 0.2255 - lr: 9.8235e-04\nEpoch 6/50\n34/34 [==============================] - 41s 1s/step - loss: 2.0219 - accuracy: 0.2063 - val_loss: 1.7549 - val_accuracy: 0.2170 - lr: 9.7884e-04\nEpoch 7/50\n34/34 [==============================] - 42s 1s/step - loss: 1.9329 - accuracy: 0.2100 - val_loss: 1.6764 - val_accuracy: 0.1894 - lr: 9.7534e-04\nEpoch 8/50\n34/34 [==============================] - 49s 1s/step - loss: 1.8827 - accuracy: 0.2220 - val_loss: 1.7078 - val_accuracy: 0.2064 - lr: 9.7185e-04\nEpoch 9/50\n34/34 [==============================] - 42s 1s/step - loss: 1.8951 - accuracy: 0.1933 - val_loss: 1.6207 - val_accuracy: 0.2468 - lr: 9.6838e-04\nEpoch 10/50\n34/34 [==============================] - 41s 1s/step - loss: 1.8008 - accuracy: 0.2350 - val_loss: 1.7198 - val_accuracy: 0.2000 - lr: 9.6491e-04\nEpoch 11/50\n34/34 [==============================] - 41s 1s/step - loss: 1.7793 - accuracy: 0.2368 - val_loss: 1.8103 - val_accuracy: 0.2298 - lr: 9.6146e-04\nEpoch 12/50\n34/34 [==============================] - 42s 1s/step - loss: 1.7683 - accuracy: 0.2155 - val_loss: 1.7499 - val_accuracy: 0.2383 - lr: 9.5802e-04\nEpoch 13/50\n34/34 [==============================] - 44s 1s/step - loss: 1.7391 - accuracy: 0.2581 - val_loss: 1.5494 - val_accuracy: 0.2809 - lr: 9.5460e-04\nEpoch 14/50\n34/34 [==============================] - 41s 1s/step - loss: 1.7216 - accuracy: 0.2276 - val_loss: 1.5573 - val_accuracy: 0.3128 - lr: 9.5119e-04\nEpoch 15/50\n34/34 [==============================] - 44s 1s/step - loss: 1.6876 - accuracy: 0.2405 - val_loss: 1.5453 - val_accuracy: 0.2936 - lr: 9.4778e-04\nEpoch 16/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6803 - accuracy: 0.2359 - val_loss: 1.5552 - val_accuracy: 0.2872 - lr: 9.4440e-04\nEpoch 17/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6414 - accuracy: 0.2710 - val_loss: 1.5583 - val_accuracy: 0.2809 - lr: 9.4102e-04\nEpoch 18/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6868 - accuracy: 0.2248 - val_loss: 1.5676 - val_accuracy: 0.2745 - lr: 9.3765e-04\nEpoch 19/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6315 - accuracy: 0.2609 - val_loss: 1.5556 - val_accuracy: 0.2979 - lr: 9.3430e-04\nEpoch 20/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6322 - accuracy: 0.2701 - val_loss: 1.5606 - val_accuracy: 0.2894 - lr: 9.3096e-04\nEpoch 21/50\n34/34 [==============================] - 41s 1s/step - loss: 1.6318 - accuracy: 0.2757 - val_loss: 1.5475 - val_accuracy: 0.2915 - lr: 9.2763e-04\nEpoch 22/50\n34/34 [==============================] - 44s 1s/step - loss: 1.6215 - accuracy: 0.2683 - val_loss: 1.5439 - val_accuracy: 0.3170 - lr: 9.2431e-04\nEpoch 23/50\n34/34 [==============================] - 44s 1s/step - loss: 1.6082 - accuracy: 0.2673 - val_loss: 1.5433 - val_accuracy: 0.3106 - lr: 9.2101e-04\nEpoch 24/50\n34/34 [==============================] - 43s 1s/step - loss: 1.6023 - accuracy: 0.2599 - val_loss: 1.5582 - val_accuracy: 0.2851 - lr: 9.1771e-04\nEpoch 25/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5949 - accuracy: 0.2812 - val_loss: 1.5617 - val_accuracy: 0.2447 - lr: 9.1443e-04\nEpoch 26/50\n34/34 [==============================] - 45s 1s/step - loss: 1.5898 - accuracy: 0.2627 - val_loss: 1.5424 - val_accuracy: 0.2787 - lr: 9.1116e-04\nEpoch 27/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5755 - accuracy: 0.3025 - val_loss: 1.5473 - val_accuracy: 0.3064 - lr: 9.0790e-04\nEpoch 28/50\n34/34 [==============================] - 44s 1s/step - loss: 1.5851 - accuracy: 0.2720 - val_loss: 1.5018 - val_accuracy: 0.3660 - lr: 9.0466e-04\nEpoch 29/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5861 - accuracy: 0.2673 - val_loss: 1.5055 - val_accuracy: 0.3787 - lr: 9.0142e-04\nEpoch 30/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5821 - accuracy: 0.2701 - val_loss: 1.5355 - val_accuracy: 0.3234 - lr: 8.9820e-04\nEpoch 31/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5691 - accuracy: 0.2923 - val_loss: 1.5068 - val_accuracy: 0.3447 - lr: 8.9499e-04\nEpoch 32/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5658 - accuracy: 0.2905 - val_loss: 1.5204 - val_accuracy: 0.3149 - lr: 8.9179e-04\nEpoch 33/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5569 - accuracy: 0.3006 - val_loss: 1.5128 - val_accuracy: 0.3383 - lr: 8.8860e-04\nEpoch 34/50\n34/34 [==============================] - 45s 1s/step - loss: 1.5494 - accuracy: 0.3016 - val_loss: 1.4867 - val_accuracy: 0.4064 - lr: 8.8542e-04\nEpoch 35/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5462 - accuracy: 0.3062 - val_loss: 1.4958 - val_accuracy: 0.3936 - lr: 8.8226e-04\nEpoch 36/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5594 - accuracy: 0.2942 - val_loss: 1.4897 - val_accuracy: 0.3745 - lr: 8.7910e-04\nEpoch 37/50\n34/34 [==============================] - 45s 1s/step - loss: 1.5349 - accuracy: 0.3182 - val_loss: 1.4814 - val_accuracy: 0.4064 - lr: 8.7596e-04\nEpoch 38/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5280 - accuracy: 0.3395 - val_loss: 1.5501 - val_accuracy: 0.3383 - lr: 8.7282e-04\nEpoch 39/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5495 - accuracy: 0.3099 - val_loss: 1.5769 - val_accuracy: 0.2660 - lr: 8.6970e-04\nEpoch 40/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5369 - accuracy: 0.2979 - val_loss: 1.4977 - val_accuracy: 0.3894 - lr: 8.6659e-04\nEpoch 41/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5294 - accuracy: 0.3312 - val_loss: 1.5083 - val_accuracy: 0.3489 - lr: 8.6350e-04\nEpoch 42/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5242 - accuracy: 0.3386 - val_loss: 1.5313 - val_accuracy: 0.2957 - lr: 8.6041e-04\nEpoch 43/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5406 - accuracy: 0.3256 - val_loss: 1.6186 - val_accuracy: 0.2447 - lr: 8.5733e-04\nEpoch 44/50\n34/34 [==============================] - 44s 1s/step - loss: 1.5427 - accuracy: 0.2858 - val_loss: 1.4583 - val_accuracy: 0.4191 - lr: 8.5426e-04\nEpoch 45/50\n34/34 [==============================] - 42s 1s/step - loss: 1.5427 - accuracy: 0.3034 - val_loss: 1.5067 - val_accuracy: 0.3766 - lr: 8.5121e-04\nEpoch 46/50\n34/34 [==============================] - 45s 1s/step - loss: 1.5257 - accuracy: 0.3238 - val_loss: 1.4435 - val_accuracy: 0.4255 - lr: 8.4817e-04\nEpoch 47/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5127 - accuracy: 0.3182 - val_loss: 1.4444 - val_accuracy: 0.4298 - lr: 8.4513e-04\nEpoch 48/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5140 - accuracy: 0.3321 - val_loss: 1.5026 - val_accuracy: 0.3468 - lr: 8.4211e-04\nEpoch 49/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5154 - accuracy: 0.3154 - val_loss: 1.4605 - val_accuracy: 0.3745 - lr: 8.3910e-04\nEpoch 50/50\n34/34 [==============================] - 41s 1s/step - loss: 1.5080 - accuracy: 0.3534 - val_loss: 1.5351 - val_accuracy: 0.3043 - lr: 8.3610e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\ntest_loss, test_acc = model.evaluate(test_generator)\nprint('Test accuracy:', test_acc)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-14T16:04:08.280050Z","iopub.execute_input":"2023-04-14T16:04:08.280881Z","iopub.status.idle":"2023-04-14T16:04:22.359395Z","shell.execute_reply.started":"2023-04-14T16:04:08.280837Z","shell.execute_reply":"2023-04-14T16:04:22.358282Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"15/15 [==============================] - 13s 921ms/step - loss: 1.5351 - accuracy: 0.3043\nTest accuracy: 0.30425530672073364\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the training history\nplt.plot(history.history['accuracy'], label='train_accuracy')\nplt.plot(history.history['val_accuracy'], label='val_accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-01T23:19:33.879562Z","iopub.execute_input":"2023-04-01T23:19:33.880004Z","iopub.status.idle":"2023-04-01T23:19:33.983049Z","shell.execute_reply.started":"2023-04-01T23:19:33.879964Z","shell.execute_reply":"2023-04-01T23:19:33.980954Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/54322615.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the training history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"],"ename":"NameError","evalue":"name 'plt' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\ndef predict_yoga_pose(image_path):\n    # Load the image\n    image = load_img(image_path, target_size=img_size)\n\n    # Convert the image to an array\n    image_array = img_to_array(image)\n    image_array = image_array / 255.0  # Rescale the image\n\n    # Expand the dimensions of the image array\n    image_array = np.expand_dims(image_array, axis=0)\n\n    # Make predictions\n    predictions = model.predict(image_array)\n\n    # Decode the predictions to get the class label\n    predicted_class = np.argmax(predictions, axis=-1)\n    class_labels = list(train_generator.class_indices.keys())\n    predicted_label = class_labels[predicted_class[0]]\n\n    return predicted_label","metadata":{"execution":{"iopub.status.busy":"2023-04-01T23:19:38.951466Z","iopub.execute_input":"2023-04-01T23:19:38.951923Z","iopub.status.idle":"2023-04-01T23:19:38.959756Z","shell.execute_reply.started":"2023-04-01T23:19:38.951882Z","shell.execute_reply":"2023-04-01T23:19:38.958767Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}